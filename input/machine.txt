The domain of Machine learning has experienced Substantial advancement and development. Recently, showcasing a Broad spectrum of uses like Computational linguistics, image identification, and autonomous systems. With the increasing demand for intelligent systems, it has become crucial to comprehend the different categories of machine acquiring knowledge systems along with their applications in the present world. This paper presents actual use cases of machine learning, including cancer classification, and how machine learning algorithms have been implemented on medical data to categorize diverse forms of cancer and anticipate their outcomes. The paper also discusses supervised, unsupervised, and reinforcement learning, highlighting the benefits and disadvantages of each category of Computational intelligence system. The conclusions of this systematic study on machine learning methods and applications in cancer classification have numerous implications. The main lesson is that through accurate classification of cancer kinds, patient outcome prediction, and identification of possible therapeutic targets, machine learning holds enormous potential for improving cancer diagnosis and therapy. This review offers readers with a broad understanding as of the present advancements in machine learning applied to cancer classification today, empowering them to decide for themselves whether to use these methods in clinical settings. Lastly, the paper wraps up by engaging in a discussion on the future of machine learning, including the potential for new types of systems to be developed as the field advances. Overall, the information included in this survey article is useful for scholars, practitioners, and individuals interested in gaining knowledge about the fundamentals of machine learning and its various applications in different areas of activities.

The inception of “machine learning” dates back to 1959, when Arthur Samuel, a pioneering figure in the domains of artificial intelligence and computer gaming hailing from the United States, coined this term. Samuel devised a program that played checkers and utilized self-play to enhance its gameplay over time, paving the way for contemporary machine-learning algorithms. Presently, machine learning has become ubiquitous in various domains like natural language processing, image recognition, and other recommendation systems. For instance, image recognition algorithms can learn from vast collections of labelled images to recognize objects in new pictures, while natural language processing algorithms can learn from massive datasets of text to detect speech or translate languages [1]. Machine learning, which falls under the umbrella of artificial intelligence and computer science, involves the development of algorithms and models that enable computers to learn and make predictions or decisions autonomously, without the need for explicit programming instructions. This involves feeding extensive data to an algorithm, enabling it to identify patterns and connections within the data. Machine learning has emerged as a pivotal technology in numerous sectors, such as healthcare, finance, and e-commerce, fundamentally transforming how we analyze data and make informed decisions. However, it also poses several challenges, such as the necessity for enormous amount of data and the comprehensibility of the decision-making procedure of the algorithm. The development of more robust and ethical machine learning systems is an ongoing research area in the field [2, 3].

Machine learning roots can be detected to the mid-twentieth century and it has since been applied in a broad spectrum of practical applications. One of the earliest examples of machine learning was Cybertron, an experimental “learning machine” created by Raytheon Company in the 1960s. This device used punched tape memory to analyze sonar data, electrocardiograms and speech patterns. The Cybertron was repeatedly underwent training by a human operator to recognize patterns and was equipped with a “goof” button to reconsider bad choices. During this period, machine learning research primarily focused on pattern categorization, as demonstrated by the book Learning Machines by Nilsson. Pattern recognition continued to be an area of interest as highlighted by Duda and Hart in 1973, In 1981, researchers presented. Studies have been conducted to train a neural network in recognizing a set of 40 characters that are commonly found in computer terminals. These characters consist of 26 letters, 10 numbers, and 4 special symbols. This marked a significant development in machine learning and paved the way for future advancements in the field [4].